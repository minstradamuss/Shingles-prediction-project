{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NUL2FQ4ShAO5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "input_file = '/content/dataset_shingles_maria_sample.json'\n",
        "output_base = 'split_file_'\n",
        "records_per_file = 200\n",
        "\n",
        "with open(input_file, 'r') as file:\n",
        "    file_count = 0\n",
        "    records = []\n",
        "\n",
        "    for line in file:\n",
        "        try:\n",
        "            record = json.loads(line)\n",
        "            records.append(record)\n",
        "\n",
        "            if len(records) == records_per_file:\n",
        "                output_file = f'{output_base}{file_count}.jsonl'\n",
        "                with open(output_file, 'w') as out_file:\n",
        "                    for rec in records:\n",
        "                        json.dump(rec, out_file)\n",
        "                        out_file.write('\\n')\n",
        "                file_count += 1\n",
        "                records = []\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON: {e}\")\n",
        "            continue\n",
        "\n",
        "    if records:\n",
        "        output_file = f'{output_base}{file_count}.jsonl'\n",
        "        with open(output_file, 'w') as out_file:\n",
        "            for rec in records:\n",
        "                json.dump(rec, out_file)\n",
        "                out_file.write('\\n')\n"
      ]
    }
  ]
}
