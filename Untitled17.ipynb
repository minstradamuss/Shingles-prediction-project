{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDs9BO2YmPOA",
        "outputId": "150cf3a9-b406-4b6f-afe2-27dc83383be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка декодирования JSON: Unterminated string starting at: line 1 column 31068 (char 31067)\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "\n",
        "def count_shingles(filename):\n",
        "    bad_texts_shingle_counts = defaultdict(int)\n",
        "    all_texts_shingle_counts = defaultdict(int)\n",
        "\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            if line.strip():\n",
        "                try:\n",
        "                    data = json.loads(line)\n",
        "\n",
        "                    for shingle in data['shingles']:\n",
        "                        all_texts_shingle_counts[shingle] += 1\n",
        "\n",
        "                    if not data['target']:\n",
        "                        for shingle in data['shingles']:\n",
        "                            bad_texts_shingle_counts[shingle] += 1\n",
        "\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Ошибка декодирования JSON: {e}\")\n",
        "\n",
        "    return bad_texts_shingle_counts, all_texts_shingle_counts\n",
        "\n",
        "def save_to_csv(bad_texts_counts, all_texts_counts, output_filename):\n",
        "    with open(output_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "\n",
        "        writer.writerow(['Shingle', 'Count in bad texts', 'Count in all texts'])\n",
        "\n",
        "        all_shingles = set(all_texts_counts.keys()).union(bad_texts_counts.keys())\n",
        "        for shingle in all_shingles:\n",
        "            writer.writerow([\n",
        "                shingle,\n",
        "                bad_texts_counts.get(shingle, 0),\n",
        "                all_texts_counts.get(shingle, 0)\n",
        "            ])\n",
        "\n",
        "filename = '/content/dataset_shingles_maria_sample.json'\n",
        "bad_texts_counts, all_texts_counts = count_shingles(filename)\n",
        "\n",
        "output_filename = 'shingle_counts.csv'\n",
        "save_to_csv(bad_texts_counts, all_texts_counts, output_filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hSbDnzyq-ZJ",
        "outputId": "4103bde9-c956-4c5d-f0a0-d41af2ccb2f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from catboost import CatBoostClassifier\n",
        "import numpy as np\n",
        "\n",
        "def load_data(filename):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    # Чтение данных из файла\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            if line.strip():\n",
        "                try:\n",
        "                    data = json.loads(line)\n",
        "                    X.append(data['shingles'])  # Шинглы - признаки\n",
        "                    y.append(int(data['target']))  # Target (0 или 1)\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Ошибка декодирования JSON: {e}\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "filename = '/content/dataset_shingles_maria_sample.json'\n",
        "X, y = load_data(filename)\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "X_transformed = mlb.fit_transform(X)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=False)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print(f\"Точность модели: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb8V2qpjpoWG",
        "outputId": "ff414436-b69d-48e7-d7be-c50abacf2680"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка декодирования JSON: Unterminated string starting at: line 1 column 5322 (char 5321)\n",
            "Точность модели: 0.9438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from catboost import CatBoostClassifier\n",
        "import numpy as np\n",
        "\n",
        "def calculate_shingle_counts(filename):\n",
        "    bad_shingle_counts = defaultdict(int)\n",
        "    all_shingle_counts = defaultdict(int)\n",
        "\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            if line.strip():\n",
        "                try:\n",
        "                    data = json.loads(line)\n",
        "                    target = data['target']\n",
        "                    shingles = data['shingles']\n",
        "                    for shingle in shingles:\n",
        "                        all_shingle_counts[shingle] += 1\n",
        "                        if not target:\n",
        "                            bad_shingle_counts[shingle] += 1\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Ошибка декодирования JSON: {e}\")\n",
        "\n",
        "    return bad_shingle_counts, all_shingle_counts\n",
        "\n",
        "def load_data_with_counts(filename, bad_shingle_counts, all_shingle_counts):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            if line.strip():\n",
        "                try:\n",
        "                    data = json.loads(line)\n",
        "                    shingles = data['shingles']\n",
        "                    target = data['target']\n",
        "\n",
        "                    # Count in bad texts / Count in all texts\n",
        "                    shingle_features = []\n",
        "                    for shingle in shingles:\n",
        "                        bad_count = bad_shingle_counts[shingle]\n",
        "                        all_count = all_shingle_counts[shingle]\n",
        "                        ratio = bad_count / all_count if all_count > 0 else 0\n",
        "                        shingle_features.append(ratio)\n",
        "\n",
        "                    X.append(shingle_features)\n",
        "                    y.append(int(target))\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Ошибка декодирования JSON: {e}\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "filename = '/content/dataset_shingles_maria_sample.json'\n",
        "bad_shingle_counts, all_shingle_counts = calculate_shingle_counts(filename)\n",
        "\n",
        "\n",
        "X, y = load_data_with_counts(filename, bad_shingle_counts, all_shingle_counts)\n",
        "\n",
        "max_shingles = max(len(x) for x in X)\n",
        "X_padded = [x + [0] * (max_shingles - len(x)) for x in X]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=False)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print(f\"Точность модели: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uthg8dYhsGdH",
        "outputId": "205d0ad1-59ad-407a-cac1-305c8e950fc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка декодирования JSON: Unterminated string starting at: line 1 column 836 (char 835)\n",
            "Ошибка декодирования JSON: Unterminated string starting at: line 1 column 836 (char 835)\n",
            "Точность модели: 0.9988\n"
          ]
        }
      ]
    }
  ]
}