{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-28T09:52:45.580309Z",
     "iopub.status.busy": "2024-11-28T09:52:45.579216Z",
     "iopub.status.idle": "2024-11-28T09:52:48.502682Z",
     "shell.execute_reply": "2024-11-28T09:52:48.501297Z",
     "shell.execute_reply.started": "2024-11-28T09:52:45.580249Z"
    },
    "id": "WNZ2RkycJcR5",
    "outputId": "af1123d1-90d3-436d-bcb0-15450e9dcbf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jsonlines in /home/jupyter/.local/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (23.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-28T09:52:48.506803Z",
     "iopub.status.busy": "2024-11-28T09:52:48.505273Z",
     "iopub.status.idle": "2024-11-28T09:53:19.292911Z",
     "shell.execute_reply": "2024-11-28T09:53:19.291759Z",
     "shell.execute_reply.started": "2024-11-28T09:52:48.506745Z"
    },
    "id": "wuH40FgTJKPj",
    "outputId": "ad9de7fd-7dfe-4283-91f9-423cc2df2836",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11523/4083175642.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['group'] = X['group'].astype('category')\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_file = '/home/jupyter/datasphere/project/split_file_0 (2).jsonl'\n",
    "\n",
    "shingle_counts = defaultdict(int)\n",
    "shingle_phishing_counts = defaultdict(int)\n",
    "\n",
    "with jsonlines.open(data_file) as reader:\n",
    "    for obj in reader:\n",
    "        num = obj['num']\n",
    "        target = obj['target']\n",
    "        for shingle in obj['shingles']:\n",
    "            shingle_counts[shingle] += num\n",
    "            if target == 1:\n",
    "                shingle_phishing_counts[shingle] += num\n",
    "\n",
    "shingle_data = []\n",
    "for shingle, count in shingle_counts.items():\n",
    "    phishing_count = shingle_phishing_counts[shingle]\n",
    "    phishing_ratio = phishing_count / count if count > 0 else 0\n",
    "    group = int(phishing_ratio * 5)\n",
    "    shingle_data.append((shingle, phishing_ratio, group))\n",
    "\n",
    "shingle_df = pd.DataFrame(shingle_data, columns=[\"shingle\", \"phishing_ratio\", \"group\"])\n",
    "\n",
    "le = LabelEncoder()\n",
    "shingle_df['shingle_id'] = le.fit_transform(shingle_df['shingle'])\n",
    "\n",
    "X = shingle_df[['shingle_id', 'phishing_ratio', 'group']]\n",
    "y = shingle_df['shingle'].apply(lambda x: 1 if x in shingle_phishing_counts and shingle_phishing_counts[x] > 0 else 0)\n",
    "\n",
    "X['group'] = X['group'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T09:53:19.295183Z",
     "iopub.status.busy": "2024-11-28T09:53:19.294125Z",
     "iopub.status.idle": "2024-11-28T09:53:19.908618Z",
     "shell.execute_reply": "2024-11-28T09:53:19.907398Z",
     "shell.execute_reply.started": "2024-11-28T09:53:19.295097Z"
    },
    "id": "hiO45AfGJT2_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_ids = torch.tensor(X_train['shingle_id'].values, dtype=torch.long)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float)\n",
    "\n",
    "train_data = TensorDataset(X_train_ids, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "X_test_ids = torch.tensor(X_test['shingle_id'].values, dtype=torch.long).view(-1)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "test_data = TensorDataset(X_test_ids, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T09:53:19.912016Z",
     "iopub.status.busy": "2024-11-28T09:53:19.910791Z",
     "iopub.status.idle": "2024-11-28T09:53:19.933943Z",
     "shell.execute_reply": "2024-11-28T09:53:19.932825Z",
     "shell.execute_reply.started": "2024-11-28T09:53:19.911948Z"
    },
    "id": "t-uk99kZGc6K"
   },
   "outputs": [],
   "source": [
    "class AutoencoderClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(AutoencoderClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.decoder = nn.Linear(hidden_dim, embedding_dim)\n",
    "        self.classifier = nn.Linear(hidden_dim, 1)  # Для бинарной классификации\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # [batch_size, embedding_dim]\n",
    "        encoded = self.encoder(embedded)  # [batch_size, hidden_dim]\n",
    "        reconstructed = self.decoder(encoded)  # [batch_size, embedding_dim]\n",
    "        logits = self.classifier(encoded).squeeze(1)  # [batch_size]\n",
    "        return logits, reconstructed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-28T09:53:19.935977Z",
     "iopub.status.busy": "2024-11-28T09:53:19.934838Z",
     "iopub.status.idle": "2024-11-28T09:53:20.221583Z",
     "shell.execute_reply": "2024-11-28T09:53:20.220416Z",
     "shell.execute_reply.started": "2024-11-28T09:53:19.935922Z"
    },
    "id": "PDalxav_AqvR",
    "outputId": "b8b0b800-31b4-45bc-f790-1f1ab8ec4b95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32])\n",
      "Targets shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Input shape: {inputs.shape}\")\n",
    "    print(f\"Targets shape: {targets.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T09:53:20.224684Z",
     "iopub.status.busy": "2024-11-28T09:53:20.223105Z",
     "iopub.status.idle": "2024-11-28T09:53:20.259313Z",
     "shell.execute_reply": "2024-11-28T09:53:20.258147Z",
     "shell.execute_reply.started": "2024-11-28T09:53:20.224629Z"
    },
    "id": "x0Jif8R5J1Do"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def train_autoencoder_with_embeddings(model, train_loader, test_loader, vocab_size, embedding_dim, epochs=10, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion_reconstruction = nn.MSELoss()\n",
    "    criterion_classification = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_reconstruction_loss = 0\n",
    "        total_classification_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs, targets = batch\n",
    "\n",
    "            logits, reconstructed = model(inputs)\n",
    "\n",
    "            loss_reconstruction = criterion_reconstruction(reconstructed, model.embedding(inputs))\n",
    "            loss_classification = criterion_classification(logits.squeeze(), targets.float())\n",
    "            loss = loss_reconstruction + loss_classification\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_reconstruction_loss += loss_reconstruction.item()\n",
    "            total_classification_loss += loss_classification.item()\n",
    "\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                inputs, targets = batch\n",
    "                logits, _ = model(inputs)\n",
    "                predictions = torch.sigmoid(logits).squeeze() > 0.5\n",
    "                all_preds.extend(predictions.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        accuracy = accuracy_score(all_targets, all_preds)\n",
    "        precision = precision_score(all_targets, all_preds, zero_division=0)\n",
    "        recall = recall_score(all_targets, all_preds, zero_division=0)\n",
    "        f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}:\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall: {recall:.4f}\")\n",
    "        print(f\"  F1 Score: {f1:.4f}\\n\")\n",
    "\n",
    "        model.train()\n",
    "\n",
    "    return accuracies, precisions, recalls, f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T09:53:20.261640Z",
     "iopub.status.busy": "2024-11-28T09:53:20.260687Z",
     "iopub.status.idle": "2024-11-28T09:53:25.552257Z",
     "shell.execute_reply": "2024-11-28T09:53:25.551066Z",
     "shell.execute_reply.started": "2024-11-28T09:53:20.261582Z"
    },
    "id": "DWhe8AaL9uwD"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(le.classes_)\n",
    "embedding_dim = 128 \n",
    "hidden_dim = 64\n",
    "epochs = 10 \n",
    "lr = 0.001\n",
    "\n",
    "model = AutoencoderClassifier(vocab_size, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T09:53:25.554829Z",
     "iopub.status.busy": "2024-11-28T09:53:25.553596Z"
    },
    "id": "AVnMpv5X8SOP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracies, precisions, recalls, f1_scores = train_autoencoder_with_embeddings(\n",
    "    model, train_loader, test_loader, vocab_size, embedding_dim, epochs=10, lr=0.001\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(range(1, epochs + 1), accuracies, label=\"Accuracy\", color='blue', marker='o')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(range(1, epochs + 1), precisions, label=\"Precision\", color='green', marker='o')\n",
    "plt.title('Precision over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(range(1, epochs + 1), recalls, label=\"Recall\", color='orange', marker='o')\n",
    "plt.title('Recall over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(range(1, epochs + 1), f1_scores, label=\"F1 Score\", color='red', marker='o')\n",
    "plt.title('F1 Score over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
